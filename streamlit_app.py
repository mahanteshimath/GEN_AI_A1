import streamlit as st
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image
import io
import os
from vae_model import VAE, Encoder, Decoder
from utils import (
    vae_loss, generate_image_grid, show_reconstructions, 
    latent_space_interpolation, plot_training_curves,
    load_cifar10_data, train_vae_epoch
)

# Page config
st.set_page_config(
    page_title="Interactive VAE Explorer",
    page_icon="üé®",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        text-align: center;
        color: #FF6B6B;
        padding: 1rem;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #4ECDC4;
        font-weight: bold;
        margin-top: 2rem;
    }
    .info-box {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #4ECDC4;
        margin: 1rem 0;
    }
    .stButton>button {
        width: 100%;
        background-color: #FF6B6B;
        color: white;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)

# Initialize session state
if 'device' not in st.session_state:
    st.session_state.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

if 'model_beta1' not in st.session_state:
    st.session_state.model_beta1 = None

if 'model_beta5' not in st.session_state:
    st.session_state.model_beta5 = None

if 'train_loader' not in st.session_state:
    st.session_state.train_loader = None
    st.session_state.test_loader = None

if 'history_beta1' not in st.session_state:
    st.session_state.history_beta1 = {'total_loss': [], 'recon_loss': [], 'kl_loss': []}

if 'history_beta5' not in st.session_state:
    st.session_state.history_beta5 = {'total_loss': [], 'recon_loss': [], 'kl_loss': []}

# Sidebar navigation
st.sidebar.title("üé® VAE Explorer")
st.sidebar.markdown("---")

page = st.sidebar.radio(
    "Navigate to:",
    ["üè† Home", "üèóÔ∏è Architecture", "üìä Dataset", "üéì Training", 
     "üé® Generate Images", "üåà Interpolation", "‚öñÔ∏è Œ≤-VAE Comparison"]
)

st.sidebar.markdown("---")
st.sidebar.markdown("### Settings")
LATENT_DIM = st.sidebar.slider("Latent Dimension", 32, 256, 128, 32)
BATCH_SIZE = st.sidebar.slider("Batch Size", 32, 256, 128, 32)

st.sidebar.markdown("---")
st.sidebar.markdown("### üñ•Ô∏è Device Selection")

# Check GPU availability
cuda_available = torch.cuda.is_available()

if cuda_available:
    st.sidebar.success(f"‚úÖ GPU Available: {torch.cuda.get_device_name(0)}")
    st.sidebar.info(f"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    
    # Device selector
    device_option = st.sidebar.radio(
        "Select Device:",
        ["GPU (CUDA)", "CPU"],
        index=0 if st.session_state.device.type == 'cuda' else 1
    )
    
    # Update device based on selection
    new_device = torch.device("cuda") if device_option == "GPU (CUDA)" else torch.device("cpu")
    
    # If device changed, move models to new device
    if new_device != st.session_state.device:
        st.session_state.device = new_device
        
        # Move existing models to new device
        if st.session_state.model_beta1 is not None:
            st.session_state.model_beta1 = st.session_state.model_beta1.to(st.session_state.device)
        if st.session_state.model_beta5 is not None:
            st.session_state.model_beta5 = st.session_state.model_beta5.to(st.session_state.device)
        
        st.sidebar.success(f"‚úÖ Switched to {st.session_state.device}")
else:
    st.sidebar.warning("‚ö†Ô∏è GPU not available")
    st.sidebar.info("Using CPU (training will be slower)")
    st.session_state.device = torch.device("cpu")

st.sidebar.markdown(f"**Current Device:** {st.session_state.device}")

# Show GPU memory usage if on CUDA
if st.session_state.device.type == 'cuda':
    allocated = torch.cuda.memory_allocated(0) / 1e9
    cached = torch.cuda.memory_reserved(0) / 1e9
    st.sidebar.text(f"Memory Used: {allocated:.2f} GB")
    st.sidebar.text(f"Memory Cached: {cached:.2f} GB")

st.sidebar.markdown("---")

# ============================================================================
# HOME PAGE
# ============================================================================
if page == "üè† Home":
    st.markdown("<h1 class='main-header'>üé® Interactive VAE Explorer</h1>", unsafe_allow_html=True)
    st.markdown("<p style='text-align: center; font-size: 1.2rem;'>Learn Variational Autoencoders Through Interactive Experimentation</p>", unsafe_allow_html=True)
    
    st.markdown("---")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("### üß† What is VAE?")
        st.markdown("""
        <div class='info-box'>
        A <b>Variational Autoencoder (VAE)</b> is a generative model that learns to:
        <ul>
            <li>Compress images into a latent space (Encoder)</li>
            <li>Reconstruct images from latent codes (Decoder)</li>
            <li>Generate new images from random noise</li>
        </ul>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("### üéØ Key Components")
        st.markdown("""
        <div class='info-box'>
        <ul>
            <li><b>Encoder:</b> Image ‚Üí (Œº, œÉ)</li>
            <li><b>Reparameterization:</b> z = Œº + œÉ √ó Œµ</li>
            <li><b>Decoder:</b> z ‚Üí Reconstructed Image</li>
            <li><b>Loss:</b> Reconstruction + KL Divergence</li>
        </ul>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("### üìö What You'll Learn")
        st.markdown("""
        <div class='info-box'>
        <ul>
            <li>How VAE architecture works</li>
            <li>Training process and loss function</li>
            <li>Generate new images</li>
            <li>Explore latent space</li>
            <li>Œ≤-VAE experiments</li>
        </ul>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    st.markdown("### üîë The VAE Formula")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("#### Reparameterization Trick")
        st.latex(r"z = \mu + \sigma \cdot \epsilon, \quad \epsilon \sim \mathcal{N}(0, I)")
        st.info("This trick allows gradients to flow through the sampling operation!")
    
    with col2:
        st.markdown("#### Loss Function (ELBO)")
        st.latex(r"\mathcal{L} = \mathcal{L}_{recon} + \beta \cdot \mathcal{L}_{KL}")
        st.info("Balance between reconstruction quality and latent regularization")
    
    st.markdown("---")
    
    st.markdown("### üöÄ Getting Started")
    st.success("üëà Use the sidebar to navigate through different sections and start exploring!")
    
    with st.expander("üìñ Quick Tutorial"):
        st.markdown("""
        1. **Dataset**: Load and explore CIFAR-10 images
        2. **Architecture**: Understand the encoder-decoder structure
        3. **Training**: Train your own VAE model
        4. **Generate**: Create new images from random noise
        5. **Interpolation**: Explore smooth transitions in latent space
        6. **Œ≤-VAE**: Experiment with different Œ≤ values
        """)

# ============================================================================
# ARCHITECTURE PAGE
# ============================================================================
elif page == "üèóÔ∏è Architecture":
    st.markdown("<h1 class='main-header'>üèóÔ∏è VAE Architecture</h1>", unsafe_allow_html=True)
    
    tab1, tab2, tab3 = st.tabs(["üìê Overview", "üîΩ Encoder", "üîº Decoder"])
    
    with tab1:
        st.markdown("### Complete VAE Pipeline")
        
        st.markdown("""
        ```
        Input Image (32√ó32√ó3)
              ‚Üì
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ ENCODER ‚îÇ  ‚Üí Compresses to latent space
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚Üì
         (Œº, log œÉ¬≤)  ‚Üí Mean and log-variance
              ‚Üì
        Reparameterization: z = Œº + œÉ √ó Œµ
              ‚Üì
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ DECODER ‚îÇ  ‚Üí Reconstructs image
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚Üì
        Output Image (32√ó32√ó3)
        ```
        """)
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("#### üìä Encoder Path")
            st.code("""
32√ó32√ó3 (Input)
  ‚Üì Conv(3‚Üí32, stride=2)
16√ó16√ó32
  ‚Üì Conv(32‚Üí64, stride=2)
8√ó8√ó64
  ‚Üì Conv(64‚Üí128, stride=2)
4√ó4√ó128
  ‚Üì Conv(128‚Üí256, stride=2)
2√ó2√ó256 = 1024
  ‚Üì Linear
Œº (128) & log œÉ¬≤ (128)
            """, language="text")
        
        with col2:
            st.markdown("#### üìä Decoder Path")
            st.code("""
z (128)
  ‚Üì Linear
1024 ‚Üí 2√ó2√ó256
  ‚Üì ConvT(256‚Üí128, stride=2)
4√ó4√ó128
  ‚Üì ConvT(128‚Üí64, stride=2)
8√ó8√ó64
  ‚Üì ConvT(64‚Üí32, stride=2)
16√ó16√ó32
  ‚Üì ConvT(32‚Üí3, stride=2)
32√ó32√ó3 (Output)
            """, language="text")
    
    with tab2:
        st.markdown("### üîΩ Encoder Network")
        st.markdown("The encoder compresses a 32√ó32√ó3 image into two vectors:")
        
        col1, col2 = st.columns(2)
        with col1:
            st.info("**Œº (mu)**: Mean of latent distribution")
        with col2:
            st.info("**log œÉ¬≤**: Log-variance (for numerical stability)")
        
        st.code("""
class Encoder(nn.Module):
    def __init__(self, latent_dim=128):
        super(Encoder, self).__init__()
        
        self.conv_layers = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(32),
            nn.LeakyReLU(0.2),
            
            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(64),
            nn.LeakyReLU(0.2),
            
            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2),
            
            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2),
        )
        
        self.fc_mu = nn.Linear(256 * 2 * 2, latent_dim)
        self.fc_logvar = nn.Linear(256 * 2 * 2, latent_dim)
        """, language="python")
    
    with tab3:
        st.markdown("### üîº Decoder Network")
        st.markdown("The decoder reconstructs images from latent vectors using transposed convolutions:")
        
        st.code("""
class Decoder(nn.Module):
    def __init__(self, latent_dim=128):
        super(Decoder, self).__init__()
        
        self.fc = nn.Sequential(
            nn.Linear(latent_dim, 256 * 2 * 2),
            nn.ReLU()
        )
        
        self.deconv_layers = nn.Sequential(
            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            
            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            
            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            
            nn.ConvTranspose2d(32, 3, kernel_size=4, stride=2, padding=1),
            nn.Tanh()  # Output in [-1, 1] range
        )
        """, language="python")
    
    st.markdown("---")
    st.markdown("### üé≤ The Reparameterization Trick")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("#### ‚ùå The Problem")
        st.warning("Direct sampling z ~ N(Œº, œÉ¬≤) is **not differentiable** - gradients can't flow back!")
        
    with col2:
        st.markdown("#### ‚úÖ The Solution")
        st.success("Sample Œµ ~ N(0, I), then compute z = Œº + œÉ √ó Œµ")
    
    st.latex(r"z = \mu + \sigma \cdot \epsilon, \quad \epsilon \sim \mathcal{N}(0, I)")
    
    st.code("""
def reparameterize(self, mu, logvar):
    std = torch.exp(0.5 * logvar)  # Convert log(œÉ¬≤) to œÉ
    epsilon = torch.randn_like(std)  # Sample from N(0,1)
    z = mu + std * epsilon  # Reparameterization
    return z
    """, language="python")

# ============================================================================
# DATASET PAGE
# ============================================================================
elif page == "üìä Dataset":
    st.markdown("<h1 class='main-header'>üìä CIFAR-10 Dataset</h1>", unsafe_allow_html=True)
    
    st.markdown("""
    <div class='info-box'>
    <b>CIFAR-10</b> contains 60,000 32√ó32 color images in 10 classes:
    <code>plane, car, bird, cat, deer, dog, frog, horse, ship, truck</code>
    </div>
    """, unsafe_allow_html=True)
    
    if st.button("üì• Load CIFAR-10 Dataset"):
        with st.spinner("Downloading and preparing CIFAR-10..."):
            train_loader, test_loader = load_cifar10_data(BATCH_SIZE)
            st.session_state.train_loader = train_loader
            st.session_state.test_loader = test_loader
        st.success("‚úÖ Dataset loaded successfully!")
    
    if st.session_state.train_loader is not None:
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Training Samples", "50,000")
        with col2:
            st.metric("Test Samples", "10,000")
        with col3:
            st.metric("Image Size", "32√ó32√ó3")
        
        st.markdown("### üñºÔ∏è Sample Images")
        
        # Show sample images
        images, labels = next(iter(st.session_state.test_loader))
        classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')
        
        fig, axes = plt.subplots(2, 8, figsize=(16, 4))
        for idx, ax in enumerate(axes.flat):
            if idx < 16:
                img = images[idx].numpy().transpose(1, 2, 0)
                img = img * 0.5 + 0.5  # Denormalize
                ax.imshow(np.clip(img, 0, 1))
                ax.set_title(classes[labels[idx]], fontsize=8)
            ax.axis('off')
        
        plt.tight_layout()
        st.pyplot(fig)
        plt.close()

# ============================================================================
# TRAINING PAGE
# ============================================================================
elif page == "üéì Training":
    st.markdown("<h1 class='main-header'>üéì Train Your VAE</h1>", unsafe_allow_html=True)
    
    if st.session_state.train_loader is None:
        st.warning("‚ö†Ô∏è Please load the dataset first from the 'üìä Dataset' page!")
    else:
        tab1, tab2 = st.tabs(["‚öôÔ∏è Training Settings", "üìà Training Progress"])
        
        with tab1:
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("### Standard VAE (Œ≤=1)")
                epochs_beta1 = st.number_input("Number of Epochs (Œ≤=1)", 1, 100, 10, key="epochs_beta1")
                lr_beta1 = st.number_input("Learning Rate", 0.0001, 0.01, 0.001, 0.0001, format="%.4f", key="lr1")
                
                if st.button("üöÄ Train VAE (Œ≤=1)", key="train1"):
                    st.session_state.model_beta1 = VAE(LATENT_DIM).to(st.session_state.device)
                    
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    loss_chart = st.empty()
                    
                    for epoch in range(epochs_beta1):
                        avg_loss, avg_recon, avg_kl = train_vae_epoch(
                            st.session_state.model_beta1,
                            st.session_state.train_loader,
                            st.session_state.device,
                            beta=1.0,
                            lr=lr_beta1
                        )
                        
                        st.session_state.history_beta1['total_loss'].append(avg_loss)
                        st.session_state.history_beta1['recon_loss'].append(avg_recon)
                        st.session_state.history_beta1['kl_loss'].append(avg_kl)
                        
                        progress_bar.progress((epoch + 1) / epochs_beta1)
                        status_text.text(f"Epoch {epoch+1}/{epochs_beta1} | Loss: {avg_loss:.4f} | Recon: {avg_recon:.4f} | KL: {avg_kl:.4f}")
                        
                        # Update chart
                        fig, ax = plt.subplots(figsize=(8, 3))
                        ax.plot(st.session_state.history_beta1['total_loss'], 'b-', label='Total')
                        ax.plot(st.session_state.history_beta1['recon_loss'], 'g-', label='Recon')
                        ax.plot(st.session_state.history_beta1['kl_loss'], 'r-', label='KL')
                        ax.set_xlabel('Epoch')
                        ax.set_ylabel('Loss')
                        ax.legend()
                        ax.grid(True, alpha=0.3)
                        loss_chart.pyplot(fig)
                        plt.close()
                    
                    st.success("‚úÖ Training complete!")
            
            with col2:
                st.markdown("### Œ≤-VAE (Œ≤=5)")
                epochs_beta5 = st.number_input("Number of Epochs (Œ≤=5)", 1, 100, 10, key="epochs_beta5")
                lr_beta5 = st.number_input("Learning Rate", 0.0001, 0.01, 0.001, 0.0001, format="%.4f", key="lr5")
                
                if st.button("üöÄ Train VAE (Œ≤=5)", key="train5"):
                    st.session_state.model_beta5 = VAE(LATENT_DIM).to(st.session_state.device)
                    
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    loss_chart = st.empty()
                    
                    for epoch in range(epochs_beta5):
                        avg_loss, avg_recon, avg_kl = train_vae_epoch(
                            st.session_state.model_beta5,
                            st.session_state.train_loader,
                            st.session_state.device,
                            beta=5.0,
                            lr=lr_beta5
                        )
                        
                        st.session_state.history_beta5['total_loss'].append(avg_loss)
                        st.session_state.history_beta5['recon_loss'].append(avg_recon)
                        st.session_state.history_beta5['kl_loss'].append(avg_kl)
                        
                        progress_bar.progress((epoch + 1) / epochs_beta5)
                        status_text.text(f"Epoch {epoch+1}/{epochs_beta5} | Loss: {avg_loss:.4f} | Recon: {avg_recon:.4f} | KL: {avg_kl:.4f}")
                        
                        # Update chart
                        fig, ax = plt.subplots(figsize=(8, 3))
                        ax.plot(st.session_state.history_beta5['total_loss'], 'b-', label='Total')
                        ax.plot(st.session_state.history_beta5['recon_loss'], 'g-', label='Recon')
                        ax.plot(st.session_state.history_beta5['kl_loss'], 'r-', label='KL')
                        ax.set_xlabel('Epoch')
                        ax.set_ylabel('Loss')
                        ax.legend()
                        ax.grid(True, alpha=0.3)
                        loss_chart.pyplot(fig)
                        plt.close()
                    
                    st.success("‚úÖ Training complete!")
        
        with tab2:
            st.markdown("### üìà Training Curves")
            
            if len(st.session_state.history_beta1['total_loss']) > 0:
                fig = plot_training_curves(st.session_state.history_beta1, "Standard VAE (Œ≤=1)")
                st.pyplot(fig)
                plt.close()
            
            if len(st.session_state.history_beta5['total_loss']) > 0:
                fig = plot_training_curves(st.session_state.history_beta5, "Œ≤-VAE (Œ≤=5)")
                st.pyplot(fig)
                plt.close()

# ============================================================================
# GENERATE PAGE
# ============================================================================
elif page == "üé® Generate Images":
    st.markdown("<h1 class='main-header'>üé® Generate New Images</h1>", unsafe_allow_html=True)
    
    st.markdown("""
    <div class='info-box'>
    Generate completely new images by sampling random latent vectors from a standard normal distribution N(0, I) 
    and passing them through the decoder.
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### Standard VAE (Œ≤=1)")
        if st.session_state.model_beta1 is None:
            st.warning("‚ö†Ô∏è Train the model first!")
        else:
            num_images1 = st.slider("Number of images", 4, 16, 16, 4, key="num1")
            seed1 = st.number_input("Random Seed", 0, 1000, 42, key="seed1")
            
            if st.button("üé≤ Generate (Œ≤=1)"):
                torch.manual_seed(seed1)
                fig = generate_image_grid(st.session_state.model_beta1, st.session_state.device, 
                                         num_images1, 4, "Generated Images (Œ≤=1)")
                st.pyplot(fig)
                plt.close()
    
    with col2:
        st.markdown("### Œ≤-VAE (Œ≤=5)")
        if st.session_state.model_beta5 is None:
            st.warning("‚ö†Ô∏è Train the model first!")
        else:
            num_images5 = st.slider("Number of images", 4, 16, 16, 4, key="num5")
            seed5 = st.number_input("Random Seed", 0, 1000, 42, key="seed5")
            
            if st.button("üé≤ Generate (Œ≤=5)"):
                torch.manual_seed(seed5)
                fig = generate_image_grid(st.session_state.model_beta5, st.session_state.device,
                                         num_images5, 4, "Generated Images (Œ≤=5)")
                st.pyplot(fig)
                plt.close()
    
    st.markdown("---")
    
    if st.session_state.model_beta1 is not None and st.session_state.test_loader is not None:
        st.markdown("### üîÑ Reconstruction Quality")
        if st.button("Show Reconstructions"):
            fig = show_reconstructions(st.session_state.model_beta1, st.session_state.test_loader, 
                                      st.session_state.device, num_images=8)
            st.pyplot(fig)
            plt.close()

# ============================================================================
# INTERPOLATION PAGE
# ============================================================================
elif page == "üåà Interpolation":
    st.markdown("<h1 class='main-header'>üåà Latent Space Interpolation</h1>", unsafe_allow_html=True)
    
    st.markdown("""
    <div class='info-box'>
    <b>Latent space interpolation</b> reveals the structure of the learned representation. 
    We smoothly transition between two random latent vectors using linear interpolation:
    </div>
    """, unsafe_allow_html=True)
    
    st.latex(r"z_{\alpha} = (1-\alpha) \cdot z_1 + \alpha \cdot z_2, \quad \alpha \in [0, 1]")
    
    if st.session_state.model_beta1 is None:
        st.warning("‚ö†Ô∏è Train a model first!")
    else:
        col1, col2 = st.columns(2)
        
        with col1:
            num_steps = st.slider("Number of interpolation steps", 5, 20, 10)
        
        with col2:
            num_rows = st.slider("Number of interpolation rows", 1, 5, 3)
        
        seed = st.number_input("Random Seed", 0, 1000, 42, key="interp_seed")
        
        if st.button("üåà Generate Interpolation"):
            torch.manual_seed(seed)
            fig = latent_space_interpolation(st.session_state.model_beta1, st.session_state.device,
                                            num_steps, num_rows)
            st.pyplot(fig)
            plt.close()
            
            st.success("‚úÖ Notice how the images smoothly transition from one to another!")
        
        with st.expander("üí° Understanding Interpolation"):
            st.markdown("""
            - **Smooth transitions** indicate a well-structured latent space
            - Each intermediate image should look realistic
            - VAE's prior regularization (KL divergence) encourages this smoothness
            - Compare with Œ≤-VAE to see how Œ≤ affects the latent space organization
            """)

# ============================================================================
# BETA-VAE COMPARISON PAGE
# ============================================================================
elif page == "‚öñÔ∏è Œ≤-VAE Comparison":
    st.markdown("<h1 class='main-header'>‚öñÔ∏è Œ≤-VAE Comparison</h1>", unsafe_allow_html=True)
    
    st.markdown("""
    <div class='info-box'>
    The <b>Œ≤ parameter</b> controls the trade-off between reconstruction quality and latent space regularization:
    </div>
    """, unsafe_allow_html=True)
    
    st.latex(r"\mathcal{L}_{\beta\text{-VAE}} = \mathcal{L}_{recon} + \beta \cdot \mathcal{L}_{KL}")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.info("**Œ≤ = 1**: Standard VAE with balanced loss")
    
    with col2:
        st.info("**Œ≤ > 1**: Stronger latent regularization ‚Üí more disentangled features")
    
    st.markdown("---")
    
    if st.session_state.model_beta1 is None or st.session_state.model_beta5 is None:
        st.warning("‚ö†Ô∏è Train both models (Œ≤=1 and Œ≤=5) first!")
    else:
        tab1, tab2, tab3 = st.tabs(["üìä Loss Comparison", "üé® Generation Comparison", "üîÑ Reconstruction Comparison"])
        
        with tab1:
            st.markdown("### Training Loss Comparison")
            
            if len(st.session_state.history_beta1['total_loss']) > 0 and len(st.session_state.history_beta5['total_loss']) > 0:
                fig, axes = plt.subplots(1, 3, figsize=(15, 4))
                
                epochs = range(1, len(st.session_state.history_beta1['total_loss']) + 1)
                
                axes[0].plot(epochs, st.session_state.history_beta1['total_loss'], 'b-', label='Œ≤=1', linewidth=2)
                axes[0].plot(epochs, st.session_state.history_beta5['total_loss'], 'r-', label='Œ≤=5', linewidth=2)
                axes[0].set_title('Total Loss')
                axes[0].set_xlabel('Epoch')
                axes[0].legend()
                axes[0].grid(True, alpha=0.3)
                
                axes[1].plot(epochs, st.session_state.history_beta1['recon_loss'], 'b-', label='Œ≤=1', linewidth=2)
                axes[1].plot(epochs, st.session_state.history_beta5['recon_loss'], 'r-', label='Œ≤=5', linewidth=2)
                axes[1].set_title('Reconstruction Loss')
                axes[1].set_xlabel('Epoch')
                axes[1].legend()
                axes[1].grid(True, alpha=0.3)
                
                axes[2].plot(epochs, st.session_state.history_beta1['kl_loss'], 'b-', label='Œ≤=1', linewidth=2)
                axes[2].plot(epochs, st.session_state.history_beta5['kl_loss'], 'r-', label='Œ≤=5', linewidth=2)
                axes[2].set_title('KL Divergence')
                axes[2].set_xlabel('Epoch')
                axes[2].legend()
                axes[2].grid(True, alpha=0.3)
                
                plt.tight_layout()
                st.pyplot(fig)
                plt.close()
        
        with tab2:
            st.markdown("### Generated Images Comparison")
            st.info("Using the **same random latent vectors** for fair comparison")
            
            seed = st.number_input("Random Seed", 0, 1000, 42, key="comp_seed")
            
            if st.button("üé≤ Compare Generations"):
                torch.manual_seed(seed)
                z = torch.randn(8, LATENT_DIM).to(st.session_state.device)
                
                st.session_state.model_beta1.eval()
                st.session_state.model_beta5.eval()
                
                with torch.no_grad():
                    gen1 = st.session_state.model_beta1.decoder(z)
                    gen5 = st.session_state.model_beta5.decoder(z)
                
                gen1 = (gen1 * 0.5 + 0.5).cpu()
                gen5 = (gen5 * 0.5 + 0.5).cpu()
                
                fig, axes = plt.subplots(2, 8, figsize=(16, 4))
                
                for i in range(8):
                    img1 = gen1[i].numpy().transpose(1, 2, 0)
                    img5 = gen5[i].numpy().transpose(1, 2, 0)
                    
                    axes[0, i].imshow(np.clip(img1, 0, 1))
                    axes[0, i].axis('off')
                    if i == 0:
                        axes[0, i].set_ylabel('Œ≤=1', fontsize=12, rotation=0, labelpad=30)
                    
                    axes[1, i].imshow(np.clip(img5, 0, 1))
                    axes[1, i].axis('off')
                    if i == 0:
                        axes[1, i].set_ylabel('Œ≤=5', fontsize=12, rotation=0, labelpad=30)
                
                plt.suptitle('Generation Comparison (Same Latent Vectors)', fontsize=14, fontweight='bold')
                plt.tight_layout()
                st.pyplot(fig)
                plt.close()
        
        with tab3:
            st.markdown("### Reconstruction Quality Comparison")
            
            if st.session_state.test_loader is not None:
                if st.button("üîç Compare Reconstructions"):
                    images, _ = next(iter(st.session_state.test_loader))
                    images = images[:6].to(st.session_state.device)
                    
                    st.session_state.model_beta1.eval()
                    st.session_state.model_beta5.eval()
                    
                    with torch.no_grad():
                        recon1, _, _ = st.session_state.model_beta1(images)
                        recon5, _, _ = st.session_state.model_beta5(images)
                    
                    images = (images * 0.5 + 0.5).cpu()
                    recon1 = (recon1 * 0.5 + 0.5).cpu()
                    recon5 = (recon5 * 0.5 + 0.5).cpu()
                    
                    fig, axes = plt.subplots(3, 6, figsize=(12, 6))
                    
                    for i in range(6):
                        orig = images[i].numpy().transpose(1, 2, 0)
                        r1 = recon1[i].numpy().transpose(1, 2, 0)
                        r5 = recon5[i].numpy().transpose(1, 2, 0)
                        
                        axes[0, i].imshow(np.clip(orig, 0, 1))
                        axes[0, i].axis('off')
                        if i == 0:
                            axes[0, i].set_ylabel('Original', fontsize=10, rotation=0, labelpad=40)
                        
                        axes[1, i].imshow(np.clip(r1, 0, 1))
                        axes[1, i].axis('off')
                        if i == 0:
                            axes[1, i].set_ylabel('Œ≤=1', fontsize=10, rotation=0, labelpad=40)
                        
                        axes[2, i].imshow(np.clip(r5, 0, 1))
                        axes[2, i].axis('off')
                        if i == 0:
                            axes[2, i].set_ylabel('Œ≤=5', fontsize=10, rotation=0, labelpad=40)
                    
                    plt.suptitle('Reconstruction Quality Comparison', fontsize=14, fontweight='bold')
                    plt.tight_layout()
                    st.pyplot(fig)
                    plt.close()
    
    st.markdown("---")
    
    with st.expander("üìä Key Observations"):
        st.markdown("""
        ### Expected Differences:
        
        1. **Reconstruction Quality**:
           - Œ≤=1: Sharper, more detailed images
           - Œ≤=5: Slightly blurrier images (stronger compression)
        
        2. **Latent Space Organization**:
           - Œ≤=1: Standard smoothness
           - Œ≤=5: More disentangled features, better interpolation
        
        3. **Loss Behavior**:
           - Œ≤=5 has higher total loss (due to Œ≤ weight)
           - Œ≤=5 has lower KL divergence (stronger regularization)
           - Œ≤=1 has lower reconstruction loss (less compression)
        
        ### The Trade-off:
        Higher Œ≤ ‚Üí Better latent structure but lower visual quality
        Lower Œ≤ ‚Üí Better visual quality but less organized latent space
        """)

st.sidebar.markdown("---")
st.sidebar.markdown("### üìù About")
st.sidebar.info("Interactive VAE Explorer - Learn Variational Autoencoders through hands-on experimentation!")

# Custom CSS for expanders and footer
st.markdown(
    '''
    <style>
    .streamlit-expanderHeader {
        background-color: blue;
        color: white; # Adjust this for expander header color
    }
    .streamlit-expanderContent {
        background-color: blue;
        color: white; # Expander content color
    }
    </style>
    ''',
    unsafe_allow_html=True
)

# Footer
footer="""<style>

.footer {
position: fixed;
left: 0;
bottom: 0;
width: 100%;
background-color: #2C1E5B;
color: white;
text-align: center;
}
</style>
<div class="footer">
<p>Developed with ‚ù§Ô∏è by <a style='display: inline; text-align: center;' href="https://www.linkedin.com/in/mahantesh-hiremath/" target="_blank">MAHANTESH HIREMATH</a></p>
</div>
"""
st.markdown(footer,unsafe_allow_html=True)
