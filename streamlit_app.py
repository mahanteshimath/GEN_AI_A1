import streamlit as st
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image
import io
import os
from vae_model import VAE, Encoder, Decoder
from utils import (
    vae_loss, generate_image_grid, show_reconstructions, 
    latent_space_interpolation, plot_training_curves,
    load_cifar10_data, train_vae_epoch
)

# Page config
st.set_page_config(
    page_title="Interactive VAE Explorer",
    page_icon="ğŸ¨",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        text-align: center;
        color: #FF6B6B;
        padding: 1rem;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #4ECDC4;
        font-weight: bold;
        margin-top: 2rem;
    }
    .info-box {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #4ECDC4;
        margin: 1rem 0;
    }
    .stButton>button {
        width: 100%;
        background-color: #FF6B6B;
        color: white;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)

# Initialize session state
if 'device' not in st.session_state:
    st.session_state.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

if 'model_beta1' not in st.session_state:
    st.session_state.model_beta1 = None

if 'model_beta5' not in st.session_state:
    st.session_state.model_beta5 = None

if 'train_loader' not in st.session_state:
    st.session_state.train_loader = None
    st.session_state.test_loader = None

if 'history_beta1' not in st.session_state:
    st.session_state.history_beta1 = {'total_loss': [], 'recon_loss': [], 'kl_loss': []}

if 'history_beta5' not in st.session_state:
    st.session_state.history_beta5 = {'total_loss': [], 'recon_loss': [], 'kl_loss': []}

# Sidebar navigation
st.sidebar.title("ğŸ¨ VAE Explorer")
st.sidebar.markdown("---")

page = st.sidebar.radio(
    "Navigate to:",
    ["ğŸ  Home", "ğŸ—ï¸ Architecture", "ğŸ“Š Dataset", "ğŸ“ Training", 
     "ğŸ¨ Generate Images", "ğŸŒˆ Interpolation", "âš–ï¸ Î²-VAE Comparison"]
)

st.sidebar.markdown("---")
st.sidebar.markdown("### Settings")
LATENT_DIM = st.sidebar.slider("Latent Dimension", 32, 256, 128, 32)
BATCH_SIZE = st.sidebar.slider("Batch Size", 32, 256, 128, 32)

st.sidebar.markdown("---")
st.sidebar.markdown(f"**Device:** {st.session_state.device}")

# ============================================================================
# HOME PAGE
# ============================================================================
if page == "ğŸ  Home":
    st.markdown("<h1 class='main-header'>ğŸ¨ Interactive VAE Explorer</h1>", unsafe_allow_html=True)
    st.markdown("<p style='text-align: center; font-size: 1.2rem;'>Learn Variational Autoencoders Through Interactive Experimentation</p>", unsafe_allow_html=True)
    
    st.markdown("---")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("### ğŸ§  What is VAE?")
        st.markdown("""
        <div class='info-box'>
        A <b>Variational Autoencoder (VAE)</b> is a generative model that learns to:
        <ul>
            <li>Compress images into a latent space (Encoder)</li>
            <li>Reconstruct images from latent codes (Decoder)</li>
            <li>Generate new images from random noise</li>
        </ul>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("### ğŸ¯ Key Components")
        st.markdown("""
        <div class='info-box'>
        <ul>
            <li><b>Encoder:</b> Image â†’ (Î¼, Ïƒ)</li>
            <li><b>Reparameterization:</b> z = Î¼ + Ïƒ Ã— Îµ</li>
            <li><b>Decoder:</b> z â†’ Reconstructed Image</li>
            <li><b>Loss:</b> Reconstruction + KL Divergence</li>
        </ul>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("### ğŸ“š What You'll Learn")
        st.markdown("""
        <div class='info-box'>
        <ul>
            <li>How VAE architecture works</li>
            <li>Training process and loss function</li>
            <li>Generate new images</li>
            <li>Explore latent space</li>
            <li>Î²-VAE experiments</li>
        </ul>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    st.markdown("### ğŸ”‘ The VAE Formula")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("#### Reparameterization Trick")
        st.latex(r"z = \mu + \sigma \cdot \epsilon, \quad \epsilon \sim \mathcal{N}(0, I)")
        st.info("This trick allows gradients to flow through the sampling operation!")
    
    with col2:
        st.markdown("#### Loss Function (ELBO)")
        st.latex(r"\mathcal{L} = \mathcal{L}_{recon} + \beta \cdot \mathcal{L}_{KL}")
        st.info("Balance between reconstruction quality and latent regularization")
    
    st.markdown("---")
    
    st.markdown("### ğŸš€ Getting Started")
    st.success("ğŸ‘ˆ Use the sidebar to navigate through different sections and start exploring!")
    
    with st.expander("ğŸ“– Quick Tutorial"):
        st.markdown("""
        1. **Dataset**: Load and explore CIFAR-10 images
        2. **Architecture**: Understand the encoder-decoder structure
        3. **Training**: Train your own VAE model
        4. **Generate**: Create new images from random noise
        5. **Interpolation**: Explore smooth transitions in latent space
        6. **Î²-VAE**: Experiment with different Î² values
        """)

# ============================================================================
# ARCHITECTURE PAGE
# ============================================================================
elif page == "ğŸ—ï¸ Architecture":
    st.markdown("<h1 class='main-header'>ğŸ—ï¸ VAE Architecture</h1>", unsafe_allow_html=True)
    
    tab1, tab2, tab3 = st.tabs(["ğŸ“ Overview", "ğŸ”½ Encoder", "ğŸ”¼ Decoder"])
    
    with tab1:
        st.markdown("### Complete VAE Pipeline")
        
        st.markdown("""
        ```
        Input Image (32Ã—32Ã—3)
              â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ ENCODER â”‚  â†’ Compresses to latent space
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
         (Î¼, log ÏƒÂ²)  â†’ Mean and log-variance
              â†“
        Reparameterization: z = Î¼ + Ïƒ Ã— Îµ
              â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ DECODER â”‚  â†’ Reconstructs image
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
        Output Image (32Ã—32Ã—3)
        ```
        """)
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("#### ğŸ“Š Encoder Path")
            st.code("""
32Ã—32Ã—3 (Input)
  â†“ Conv(3â†’32, stride=2)
16Ã—16Ã—32
  â†“ Conv(32â†’64, stride=2)
8Ã—8Ã—64
  â†“ Conv(64â†’128, stride=2)
4Ã—4Ã—128
  â†“ Conv(128â†’256, stride=2)
2Ã—2Ã—256 = 1024
  â†“ Linear
Î¼ (128) & log ÏƒÂ² (128)
            """, language="text")
        
        with col2:
            st.markdown("#### ğŸ“Š Decoder Path")
            st.code("""
z (128)
  â†“ Linear
1024 â†’ 2Ã—2Ã—256
  â†“ ConvT(256â†’128, stride=2)
4Ã—4Ã—128
  â†“ ConvT(128â†’64, stride=2)
8Ã—8Ã—64
  â†“ ConvT(64â†’32, stride=2)
16Ã—16Ã—32
  â†“ ConvT(32â†’3, stride=2)
32Ã—32Ã—3 (Output)
            """, language="text")
    
    with tab2:
        st.markdown("### ğŸ”½ Encoder Network")
        st.markdown("The encoder compresses a 32Ã—32Ã—3 image into two vectors:")
        
        col1, col2 = st.columns(2)
        with col1:
            st.info("**Î¼ (mu)**: Mean of latent distribution")
        with col2:
            st.info("**log ÏƒÂ²**: Log-variance (for numerical stability)")
        
        st.code("""
class Encoder(nn.Module):
    def __init__(self, latent_dim=128):
        super(Encoder, self).__init__()
        
        self.conv_layers = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(32),
            nn.LeakyReLU(0.2),
            
            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(64),
            nn.LeakyReLU(0.2),
            
            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2),
            
            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2),
        )
        
        self.fc_mu = nn.Linear(256 * 2 * 2, latent_dim)
        self.fc_logvar = nn.Linear(256 * 2 * 2, latent_dim)
        """, language="python")
    
    with tab3:
        st.markdown("### ğŸ”¼ Decoder Network")
        st.markdown("The decoder reconstructs images from latent vectors using transposed convolutions:")
        
        st.code("""
class Decoder(nn.Module):
    def __init__(self, latent_dim=128):
        super(Decoder, self).__init__()
        
        self.fc = nn.Sequential(
            nn.Linear(latent_dim, 256 * 2 * 2),
            nn.ReLU()
        )
        
        self.deconv_layers = nn.Sequential(
            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            
            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            
            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            
            nn.ConvTranspose2d(32, 3, kernel_size=4, stride=2, padding=1),
            nn.Tanh()  # Output in [-1, 1] range
        )
        """, language="python")
    
    st.markdown("---")
    st.markdown("### ğŸ² The Reparameterization Trick")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("#### âŒ The Problem")
        st.warning("Direct sampling z ~ N(Î¼, ÏƒÂ²) is **not differentiable** - gradients can't flow back!")
        
    with col2:
        st.markdown("#### âœ… The Solution")
        st.success("Sample Îµ ~ N(0, I), then compute z = Î¼ + Ïƒ Ã— Îµ")
    
    st.latex(r"z = \mu + \sigma \cdot \epsilon, \quad \epsilon \sim \mathcal{N}(0, I)")
    
    st.code("""
def reparameterize(self, mu, logvar):
    std = torch.exp(0.5 * logvar)  # Convert log(ÏƒÂ²) to Ïƒ
    epsilon = torch.randn_like(std)  # Sample from N(0,1)
    z = mu + std * epsilon  # Reparameterization
    return z
    """, language="python")

# ============================================================================
# DATASET PAGE
# ============================================================================
elif page == "ğŸ“Š Dataset":
    st.markdown("<h1 class='main-header'>ğŸ“Š CIFAR-10 Dataset</h1>", unsafe_allow_html=True)
    
    st.markdown("""
    <div class='info-box'>
    <b>CIFAR-10</b> contains 60,000 32Ã—32 color images in 10 classes:
    <code>plane, car, bird, cat, deer, dog, frog, horse, ship, truck</code>
    </div>
    """, unsafe_allow_html=True)
    
    if st.button("ğŸ“¥ Load CIFAR-10 Dataset"):
        with st.spinner("Downloading and preparing CIFAR-10..."):
            train_loader, test_loader = load_cifar10_data(BATCH_SIZE)
            st.session_state.train_loader = train_loader
            st.session_state.test_loader = test_loader
        st.success("âœ… Dataset loaded successfully!")
    
    if st.session_state.train_loader is not None:
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Training Samples", "50,000")
        with col2:
            st.metric("Test Samples", "10,000")
        with col3:
            st.metric("Image Size", "32Ã—32Ã—3")
        
        st.markdown("### ğŸ–¼ï¸ Sample Images")
        
        # Show sample images
        images, labels = next(iter(st.session_state.test_loader))
        classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')
        
        fig, axes = plt.subplots(2, 8, figsize=(16, 4))
        for idx, ax in enumerate(axes.flat):
            if idx < 16:
                img = images[idx].numpy().transpose(1, 2, 0)
                img = img * 0.5 + 0.5  # Denormalize
                ax.imshow(np.clip(img, 0, 1))
                ax.set_title(classes[labels[idx]], fontsize=8)
            ax.axis('off')
        
        plt.tight_layout()
        st.pyplot(fig)
        plt.close()

# ============================================================================
# TRAINING PAGE
# ============================================================================
elif page == "ğŸ“ Training":
    st.markdown("<h1 class='main-header'>ğŸ“ Train Your VAE</h1>", unsafe_allow_html=True)
    
    if st.session_state.train_loader is None:
        st.warning("âš ï¸ Please load the dataset first from the 'ğŸ“Š Dataset' page!")
    else:
        tab1, tab2 = st.tabs(["âš™ï¸ Training Settings", "ğŸ“ˆ Training Progress"])
        
        with tab1:
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("### Standard VAE (Î²=1)")
                epochs_beta1 = st.number_input("Number of Epochs (Î²=1)", 1, 100, 10, key="epochs_beta1")
                lr_beta1 = st.number_input("Learning Rate", 0.0001, 0.01, 0.001, 0.0001, format="%.4f", key="lr1")
                
                if st.button("ğŸš€ Train VAE (Î²=1)", key="train1"):
                    st.session_state.model_beta1 = VAE(LATENT_DIM).to(st.session_state.device)
                    
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    loss_chart = st.empty()
                    
                    for epoch in range(epochs_beta1):
                        avg_loss, avg_recon, avg_kl = train_vae_epoch(
                            st.session_state.model_beta1,
                            st.session_state.train_loader,
                            st.session_state.device,
                            beta=1.0,
                            lr=lr_beta1
                        )
                        
                        st.session_state.history_beta1['total_loss'].append(avg_loss)
                        st.session_state.history_beta1['recon_loss'].append(avg_recon)
                        st.session_state.history_beta1['kl_loss'].append(avg_kl)
                        
                        progress_bar.progress((epoch + 1) / epochs_beta1)
                        status_text.text(f"Epoch {epoch+1}/{epochs_beta1} | Loss: {avg_loss:.4f} | Recon: {avg_recon:.4f} | KL: {avg_kl:.4f}")
                        
                        # Update chart
                        fig, ax = plt.subplots(figsize=(8, 3))
                        ax.plot(st.session_state.history_beta1['total_loss'], 'b-', label='Total')
                        ax.plot(st.session_state.history_beta1['recon_loss'], 'g-', label='Recon')
                        ax.plot(st.session_state.history_beta1['kl_loss'], 'r-', label='KL')
                        ax.set_xlabel('Epoch')
                        ax.set_ylabel('Loss')
                        ax.legend()
                        ax.grid(True, alpha=0.3)
                        loss_chart.pyplot(fig)
                        plt.close()
                    
                    st.success("âœ… Training complete!")
            
            with col2:
                st.markdown("### Î²-VAE (Î²=5)")
                epochs_beta5 = st.number_input("Number of Epochs (Î²=5)", 1, 100, 10, key="epochs_beta5")
                lr_beta5 = st.number_input("Learning Rate", 0.0001, 0.01, 0.001, 0.0001, format="%.4f", key="lr5")
                
                if st.button("ğŸš€ Train VAE (Î²=5)", key="train5"):
                    st.session_state.model_beta5 = VAE(LATENT_DIM).to(st.session_state.device)
                    
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    loss_chart = st.empty()
                    
                    for epoch in range(epochs_beta5):
                        avg_loss, avg_recon, avg_kl = train_vae_epoch(
                            st.session_state.model_beta5,
                            st.session_state.train_loader,
                            st.session_state.device,
                            beta=5.0,
                            lr=lr_beta5
                        )
                        
                        st.session_state.history_beta5['total_loss'].append(avg_loss)
                        st.session_state.history_beta5['recon_loss'].append(avg_recon)
                        st.session_state.history_beta5['kl_loss'].append(avg_kl)
                        
                        progress_bar.progress((epoch + 1) / epochs_beta5)
                        status_text.text(f"Epoch {epoch+1}/{epochs_beta5} | Loss: {avg_loss:.4f} | Recon: {avg_recon:.4f} | KL: {avg_kl:.4f}")
                        
                        # Update chart
                        fig, ax = plt.subplots(figsize=(8, 3))
                        ax.plot(st.session_state.history_beta5['total_loss'], 'b-', label='Total')
                        ax.plot(st.session_state.history_beta5['recon_loss'], 'g-', label='Recon')
                        ax.plot(st.session_state.history_beta5['kl_loss'], 'r-', label='KL')
                        ax.set_xlabel('Epoch')
                        ax.set_ylabel('Loss')
                        ax.legend()
                        ax.grid(True, alpha=0.3)
                        loss_chart.pyplot(fig)
                        plt.close()
                    
                    st.success("âœ… Training complete!")
        
        with tab2:
            st.markdown("### ğŸ“ˆ Training Curves")
            
            if len(st.session_state.history_beta1['total_loss']) > 0:
                fig = plot_training_curves(st.session_state.history_beta1, "Standard VAE (Î²=1)")
                st.pyplot(fig)
                plt.close()
            
            if len(st.session_state.history_beta5['total_loss']) > 0:
                fig = plot_training_curves(st.session_state.history_beta5, "Î²-VAE (Î²=5)")
                st.pyplot(fig)
                plt.close()

# ============================================================================
# GENERATE PAGE
# ============================================================================
elif page == "ğŸ¨ Generate Images":
    st.markdown("<h1 class='main-header'>ğŸ¨ Generate New Images</h1>", unsafe_allow_html=True)
    
    st.markdown("""
    <div class='info-box'>
    Generate completely new images by sampling random latent vectors from a standard normal distribution N(0, I) 
    and passing them through the decoder.
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### Standard VAE (Î²=1)")
        if st.session_state.model_beta1 is None:
            st.warning("âš ï¸ Train the model first!")
        else:
            num_images1 = st.slider("Number of images", 4, 16, 16, 4, key="num1")
            seed1 = st.number_input("Random Seed", 0, 1000, 42, key="seed1")
            
            if st.button("ğŸ² Generate (Î²=1)"):
                torch.manual_seed(seed1)
                fig = generate_image_grid(st.session_state.model_beta1, st.session_state.device, 
                                         num_images1, 4, "Generated Images (Î²=1)")
                st.pyplot(fig)
                plt.close()
    
    with col2:
        st.markdown("### Î²-VAE (Î²=5)")
        if st.session_state.model_beta5 is None:
            st.warning("âš ï¸ Train the model first!")
        else:
            num_images5 = st.slider("Number of images", 4, 16, 16, 4, key="num5")
            seed5 = st.number_input("Random Seed", 0, 1000, 42, key="seed5")
            
            if st.button("ğŸ² Generate (Î²=5)"):
                torch.manual_seed(seed5)
                fig = generate_image_grid(st.session_state.model_beta5, st.session_state.device,
                                         num_images5, 4, "Generated Images (Î²=5)")
                st.pyplot(fig)
                plt.close()
    
    st.markdown("---")
    
    if st.session_state.model_beta1 is not None and st.session_state.test_loader is not None:
        st.markdown("### ğŸ”„ Reconstruction Quality")
        if st.button("Show Reconstructions"):
            fig = show_reconstructions(st.session_state.model_beta1, st.session_state.test_loader, 
                                      st.session_state.device, num_images=8)
            st.pyplot(fig)
            plt.close()

# ============================================================================
# INTERPOLATION PAGE
# ============================================================================
elif page == "ğŸŒˆ Interpolation":
    st.markdown("<h1 class='main-header'>ğŸŒˆ Latent Space Interpolation</h1>", unsafe_allow_html=True)
    
    st.markdown("""
    <div class='info-box'>
    <b>Latent space interpolation</b> reveals the structure of the learned representation. 
    We smoothly transition between two random latent vectors using linear interpolation:
    </div>
    """, unsafe_allow_html=True)
    
    st.latex(r"z_{\alpha} = (1-\alpha) \cdot z_1 + \alpha \cdot z_2, \quad \alpha \in [0, 1]")
    
    if st.session_state.model_beta1 is None:
        st.warning("âš ï¸ Train a model first!")
    else:
        col1, col2 = st.columns(2)
        
        with col1:
            num_steps = st.slider("Number of interpolation steps", 5, 20, 10)
        
        with col2:
            num_rows = st.slider("Number of interpolation rows", 1, 5, 3)
        
        seed = st.number_input("Random Seed", 0, 1000, 42, key="interp_seed")
        
        if st.button("ğŸŒˆ Generate Interpolation"):
            torch.manual_seed(seed)
            fig = latent_space_interpolation(st.session_state.model_beta1, st.session_state.device,
                                            num_steps, num_rows)
            st.pyplot(fig)
            plt.close()
            
            st.success("âœ… Notice how the images smoothly transition from one to another!")
        
        with st.expander("ğŸ’¡ Understanding Interpolation"):
            st.markdown("""
            - **Smooth transitions** indicate a well-structured latent space
            - Each intermediate image should look realistic
            - VAE's prior regularization (KL divergence) encourages this smoothness
            - Compare with Î²-VAE to see how Î² affects the latent space organization
            """)

# ============================================================================
# BETA-VAE COMPARISON PAGE
# ============================================================================
elif page == "âš–ï¸ Î²-VAE Comparison":
    st.markdown("<h1 class='main-header'>âš–ï¸ Î²-VAE Comparison</h1>", unsafe_allow_html=True)
    
    st.markdown("""
    <div class='info-box'>
    The <b>Î² parameter</b> controls the trade-off between reconstruction quality and latent space regularization:
    </div>
    """, unsafe_allow_html=True)
    
    st.latex(r"\mathcal{L}_{\beta\text{-VAE}} = \mathcal{L}_{recon} + \beta \cdot \mathcal{L}_{KL}")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.info("**Î² = 1**: Standard VAE with balanced loss")
    
    with col2:
        st.info("**Î² > 1**: Stronger latent regularization â†’ more disentangled features")
    
    st.markdown("---")
    
    if st.session_state.model_beta1 is None or st.session_state.model_beta5 is None:
        st.warning("âš ï¸ Train both models (Î²=1 and Î²=5) first!")
    else:
        tab1, tab2, tab3 = st.tabs(["ğŸ“Š Loss Comparison", "ğŸ¨ Generation Comparison", "ğŸ”„ Reconstruction Comparison"])
        
        with tab1:
            st.markdown("### Training Loss Comparison")
            
            if len(st.session_state.history_beta1['total_loss']) > 0 and len(st.session_state.history_beta5['total_loss']) > 0:
                fig, axes = plt.subplots(1, 3, figsize=(15, 4))
                
                epochs = range(1, len(st.session_state.history_beta1['total_loss']) + 1)
                
                axes[0].plot(epochs, st.session_state.history_beta1['total_loss'], 'b-', label='Î²=1', linewidth=2)
                axes[0].plot(epochs, st.session_state.history_beta5['total_loss'], 'r-', label='Î²=5', linewidth=2)
                axes[0].set_title('Total Loss')
                axes[0].set_xlabel('Epoch')
                axes[0].legend()
                axes[0].grid(True, alpha=0.3)
                
                axes[1].plot(epochs, st.session_state.history_beta1['recon_loss'], 'b-', label='Î²=1', linewidth=2)
                axes[1].plot(epochs, st.session_state.history_beta5['recon_loss'], 'r-', label='Î²=5', linewidth=2)
                axes[1].set_title('Reconstruction Loss')
                axes[1].set_xlabel('Epoch')
                axes[1].legend()
                axes[1].grid(True, alpha=0.3)
                
                axes[2].plot(epochs, st.session_state.history_beta1['kl_loss'], 'b-', label='Î²=1', linewidth=2)
                axes[2].plot(epochs, st.session_state.history_beta5['kl_loss'], 'r-', label='Î²=5', linewidth=2)
                axes[2].set_title('KL Divergence')
                axes[2].set_xlabel('Epoch')
                axes[2].legend()
                axes[2].grid(True, alpha=0.3)
                
                plt.tight_layout()
                st.pyplot(fig)
                plt.close()
        
        with tab2:
            st.markdown("### Generated Images Comparison")
            st.info("Using the **same random latent vectors** for fair comparison")
            
            seed = st.number_input("Random Seed", 0, 1000, 42, key="comp_seed")
            
            if st.button("ğŸ² Compare Generations"):
                torch.manual_seed(seed)
                z = torch.randn(8, LATENT_DIM).to(st.session_state.device)
                
                st.session_state.model_beta1.eval()
                st.session_state.model_beta5.eval()
                
                with torch.no_grad():
                    gen1 = st.session_state.model_beta1.decoder(z)
                    gen5 = st.session_state.model_beta5.decoder(z)
                
                gen1 = (gen1 * 0.5 + 0.5).cpu()
                gen5 = (gen5 * 0.5 + 0.5).cpu()
                
                fig, axes = plt.subplots(2, 8, figsize=(16, 4))
                
                for i in range(8):
                    img1 = gen1[i].numpy().transpose(1, 2, 0)
                    img5 = gen5[i].numpy().transpose(1, 2, 0)
                    
                    axes[0, i].imshow(np.clip(img1, 0, 1))
                    axes[0, i].axis('off')
                    if i == 0:
                        axes[0, i].set_ylabel('Î²=1', fontsize=12, rotation=0, labelpad=30)
                    
                    axes[1, i].imshow(np.clip(img5, 0, 1))
                    axes[1, i].axis('off')
                    if i == 0:
                        axes[1, i].set_ylabel('Î²=5', fontsize=12, rotation=0, labelpad=30)
                
                plt.suptitle('Generation Comparison (Same Latent Vectors)', fontsize=14, fontweight='bold')
                plt.tight_layout()
                st.pyplot(fig)
                plt.close()
        
        with tab3:
            st.markdown("### Reconstruction Quality Comparison")
            
            if st.session_state.test_loader is not None:
                if st.button("ğŸ” Compare Reconstructions"):
                    images, _ = next(iter(st.session_state.test_loader))
                    images = images[:6].to(st.session_state.device)
                    
                    st.session_state.model_beta1.eval()
                    st.session_state.model_beta5.eval()
                    
                    with torch.no_grad():
                        recon1, _, _ = st.session_state.model_beta1(images)
                        recon5, _, _ = st.session_state.model_beta5(images)
                    
                    images = (images * 0.5 + 0.5).cpu()
                    recon1 = (recon1 * 0.5 + 0.5).cpu()
                    recon5 = (recon5 * 0.5 + 0.5).cpu()
                    
                    fig, axes = plt.subplots(3, 6, figsize=(12, 6))
                    
                    for i in range(6):
                        orig = images[i].numpy().transpose(1, 2, 0)
                        r1 = recon1[i].numpy().transpose(1, 2, 0)
                        r5 = recon5[i].numpy().transpose(1, 2, 0)
                        
                        axes[0, i].imshow(np.clip(orig, 0, 1))
                        axes[0, i].axis('off')
                        if i == 0:
                            axes[0, i].set_ylabel('Original', fontsize=10, rotation=0, labelpad=40)
                        
                        axes[1, i].imshow(np.clip(r1, 0, 1))
                        axes[1, i].axis('off')
                        if i == 0:
                            axes[1, i].set_ylabel('Î²=1', fontsize=10, rotation=0, labelpad=40)
                        
                        axes[2, i].imshow(np.clip(r5, 0, 1))
                        axes[2, i].axis('off')
                        if i == 0:
                            axes[2, i].set_ylabel('Î²=5', fontsize=10, rotation=0, labelpad=40)
                    
                    plt.suptitle('Reconstruction Quality Comparison', fontsize=14, fontweight='bold')
                    plt.tight_layout()
                    st.pyplot(fig)
                    plt.close()
    
    st.markdown("---")
    
    with st.expander("ğŸ“Š Key Observations"):
        st.markdown("""
        ### Expected Differences:
        
        1. **Reconstruction Quality**:
           - Î²=1: Sharper, more detailed images
           - Î²=5: Slightly blurrier images (stronger compression)
        
        2. **Latent Space Organization**:
           - Î²=1: Standard smoothness
           - Î²=5: More disentangled features, better interpolation
        
        3. **Loss Behavior**:
           - Î²=5 has higher total loss (due to Î² weight)
           - Î²=5 has lower KL divergence (stronger regularization)
           - Î²=1 has lower reconstruction loss (less compression)
        
        ### The Trade-off:
        Higher Î² â†’ Better latent structure but lower visual quality
        Lower Î² â†’ Better visual quality but less organized latent space
        """)

st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ“ About")
st.sidebar.info("Interactive VAE Explorer - Learn Variational Autoencoders through hands-on experimentation!")
